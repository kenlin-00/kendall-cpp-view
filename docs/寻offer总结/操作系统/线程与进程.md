<font color="green" size=4>更多读书笔记关注公众号:**零K同学**</font>

- [并发和并行有什么区别](#并发和并行有什么区别)
- [进程的基本状态以及它们的转化](#进程的基本状态以及它们的转化)
- [什么是程序控制块PCB](#什么是程序控制块pcb)
  - [每个 PCB 是如何组织的呢](#每个-pcb-是如何组织的呢)
- [进程的上下文切换](#进程的上下文切换)
  - [发生进程上下文切换有哪些场景](#发生进程上下文切换有哪些场景)
- [进程、线程、协程(区别)](#进程线程协程区别)
- [线程上下文切换的是什么](#线程上下文切换的是什么)
- [线程的实现](#线程的实现)
- [进程的调度时机](#进程的调度时机)
  - [进程调度算法](#进程调度算法)
    - [先来先服务调度算法](#先来先服务调度算法)
    - [最短作业优先调度算法](#最短作业优先调度算法)
    - [高响应比优先调度算法](#高响应比优先调度算法)
    - [时间片轮转调度算法](#时间片轮转调度算法)
    - [最高优先级调度算法](#最高优先级调度算法)
    - [多级反馈队列调度算法](#多级反馈队列调度算法)
  - [进程优先级的字段](#进程优先级的字段)
- [进程间通信](#进程间通信)
  - [管道的创建与原理](#管道的创建与原理)
  - [那么管道是怎么实现跨越两个进程通讯的呢](#那么管道是怎么实现跨越两个进程通讯的呢)
  - [信号量的两种原子操作](#信号量的两种原子操作)
- [多线程和多线程的应用](#多线程和多线程的应用)
  - [什么时候用多进程，什么时候用多线程](#什么时候用多进程什么时候用多线程)
- [为什么会有线程安全问题](#为什么会有线程安全问题)
- [进程_线程的互斥与同步的实现和使用](#进程_线程的互斥与同步的实现和使用)
- [进程同步方式](#进程同步方式)
- [线程同步的方式](#线程同步的方式)
- [经典同步问题](#经典同步问题)
  - [哲学家就餐问题](#哲学家就餐问题)
  - [读者写者问题](#读者写者问题)
- [怎么回收线程？有哪几种方法？](#怎么回收线程有哪几种方法)
- [Linux理论上最多可以创建多少个进程](#linux理论上最多可以创建多少个进程)
- [一个进程可以创建多少线程，和什么有关](#一个进程可以创建多少线程和什么有关)
- [守护进程、僵尸进程和孤儿进程](#守护进程僵尸进程和孤儿进程)
  - [守护进程](#守护进程)
  - [孤儿进程](#孤儿进程)
  - [僵尸进程](#僵尸进程)
  - [孤儿进程和僵尸进程分别是什么，怎么形成的？](#孤儿进程和僵尸进程分别是什么怎么形成的)
  - [如何避免僵尸进程？](#如何避免僵尸进程)
- [用户态和内核态的区别](#用户态和内核态的区别)
- [阻塞与非阻塞的区别](#阻塞与非阻塞的区别)
- [线程池问题](#线程池问题)
  - [线程池的概念](#线程池的概念)
  - [线程池的组成](#线程池的组成)
  - [实现线程池的具体步骤](#实现线程池的具体步骤)
  - [线程池工作的四种情况](#线程池工作的四种情况)
  - [如何保证线程池是线程安全的](#如何保证线程池是线程安全的)
  - [当有一个任务进入任务队列时，其他阻塞线程是如何获取并执行这个任务的](#当有一个任务进入任务队列时其他阻塞线程是如何获取并执行这个任务的)

--------

## 并发和并行有什么区别

在单核CPU的某一个瞬间只会运行一个程序，但是一个期间内，就会运行很多个进程，它们之间的切换非常快，让人产生并行的错觉，实际上是并发执行的。


- **并发**就是一段时间内多个任务被处理，但是在同一个时刻，只有一个任务在执行
- **并行**就是在同一时刻，有多个任务在执行，这个需要多核 CPU 才能完成

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/并发并行.4yasajdkbdo0.png)



## 进程的基本状态以及它们的转化

- 就绪状态：其他资源准备好，只差`CPU`资源的状态就称为就绪状态，只要获得`CPU`的使用权，就可以独立运行。
- 执行状态：进程获得`CPU`资源，程序正在处理器上执行，在单处理机中(`1`核)，在某个时刻最多只能有一个进程正在执行
- 阻塞状态：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；

当然，进程另外两个基本状态：

- 创建状态（new）：进程正在被创建时的状态；
- 结束状态（Exit）：进程正在从系统中消失时的状态；

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/进程的状态.7e6q9ri1vzc0.png)

当一个进程获取 CPU 时，就会**从就绪状态转成执行状态**，当一个进程被剥夺 `CPU` 时，比如系统分配的时间片被用完，或者出现优先级更高的进程，就会**由运行状态变成就绪状态**，当一个运行进程由于某事件被阻时，比如申请资源被占用、启动 I/O 传输未完成，状态就会由 **运行状态变成阻塞状态**，当所有的等待事件发生时，比如得到申请资源、I/O 参数完成，状态就由 **阻塞变成就绪**。

> - 实际上进程还有另外一个状态 ---- **挂起状态**
> 
> 因为如果大量的进程处于阻塞状态，可能会一直占用着物理内存，当然这不是我们希望的，毕竟物理内存是有限的，所以在虚拟内存管理的操作系统中，通常会把阻塞状态的物理内存空间切换到硬盘，等需要运行的时候再从硬盘中换回到物理内存。那么就需要一个新的状态来**描述有没有占用实际物理内存的情况，这个状态就是挂起状态**，这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。
>
> 另外，挂起状态可以分为两种：
>
>   1. 阻塞挂起状态：进程在硬盘中（外存），等待某个事件出现
>   2. 就绪挂起状态：进程在硬盘中（外存），但主要进入内存就会立即执行。

## 什么是程序控制块PCB

PCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。

PCB 还用于记录**当前进程的状态**和**控制进程运行的全部信息**

### 每个 PCB 是如何组织的呢

通常是通过**链表**的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。。比如：

- 将所有处于就绪状态的进程链在一起，称为**就绪队列**；
- 把所有因等待某事件而处于等待状态的进程链在一起就组成各种**阻塞队列**；
- 另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。

除了链接的组织方式，还有**索引方式**，它的工作原理：**将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。**

一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。

## 进程的上下文切换

各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这样**一个进程切换到另一个进程运行，称为进程的上下文切换**。

进程是由内核管理和调度的，所以进程的切换只能发生在内核态。

所以，进程的上下文切换不仅包含了**虚拟内存、栈、全局变量**等用户空间的资源，还包括了**内核堆、栈、寄存器**等内核空间的资源。

通常，会把交换的信息保存在进程的 PCB，当正在运行另外一个进程的时候要切换到这个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/进程上下文.22teesvhcg5c.png)

> 但是需要注意的是，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。


### 发生进程上下文切换有哪些场景

- 当一个进程的**CPU 时间片用完**了的时候，这个进程就会由运行状态变成就绪状态，然后系统从就绪队列中选择另外一个进程运行。
- 当一个进程在**系统资源不足**，要等系统资源满足的时候才会被运行，这时候这个进程就会被挂起，然后调度其他进程先运行。
- 当一个进程通过**睡眠函数 `sleep` 主动挂起**的时候，自然也会进程调度，发生进程上下文切换。
- 当有**优先级更高的进程运行**时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；
- 发生**硬件中断**时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；

## 进程、线程、协程(区别)

- 进程: 直观的说，就是保存在硬盘中的程序在运行以后，那么这个运行起来的执行程序就是进程了。另外，操作系统会**以进程为单位**进行分配资源，比如说`CPU`时间片，内存等资源。**进程是资源分配的最小单位**。

- 刚刚说到系统运行一个可执行程序就是进程，那么线程就是这个执行程序的基本单位，也可以说是**轻量级的进程**，<font color=#268bd2> 线程是操作系统进行 CPU 调度的最小单位</font>。然后每个进程都有一个唯一的主线程，主线程和进程是相互依存的，主线程结束进程也会终止。

- 进程和线程属于包含关系，没有线程的进程可以看做是单线程的，如果一个进程内有多个线程，则执行过程不是一个线程完成的，而是多个线程共同完成的；线程是进程的一部分。另外线程可以共享它对应进程的系统资源。

- 在系统开销方面，每个进程都有独立的代码和数据空间（也就是程序的上下文），进程之间的切换会有较大的开销，因为涉及到系统的资源分配；线程因为是轻量级的进程，所以线程的切换开销小很多。而且同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；


- 还有在 linux 中进程和线程实际上都是用一个结构体 task_struct 来表示执行任务的实体。进程的创建是调用 fork 函数，而线程的创建这是 thread_create 方法，但是这两个方法内部都调用了 do_fork 来具体实现，它们的区别在于插入的参数不同，创建线程需要传入参数来设置共享资源。

- 实际上，linux 内核中实际上根本没有实现线程，它创建的就是进程，只不过通过参数指定多个进程之间共享资源（如虚拟内存，页表，文件描述符），函数调用栈，寄存器等线程私有数据则就独立。


- 协程：**协程是一种用户态的轻量级线程**，协程的调度完全由用户控制，协程拥有自己的寄存器上下文和栈，协程在调度切换的时候，将寄存器上下文保存在其他地方，在需要切换回来的时候恢复之前保存的寄存器上下文和栈，这种直接去操作栈而不是不是函数调用，也不是多线程执行，所以省去了线程切换的开销，效率很高，并且不需要多线程间的锁机制，不会发生变量写冲突。


> 说完这些再继续说 线程进程和线程的上下文切换，切换场景，接着说 linux 内核中线程的实现

## 线程上下文切换的是什么

这还得看线程是不是属于同一个进程：

- 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
- 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的**私有数据、寄存器**等不共享的数据；

所以，线程的上下文切换相比进程，开销要小很多。

## 线程的实现

linux 把所有线程当做进程来实现，每个线程有自己唯一的 task_struct 结构体.

- **首先是创建线程**

线程的创建和普通进程的创建类似，只不过在调用 `clone()` 的时候需要传递一些参数标志来指明需要共享的资源

- **接着是内核线程**

因为内核经常需要在后台执行一些操作，这种任务可以通过**内核线程**完成。内核线程就是**独立运行**在内核空间的标准进程。内核线程 和 普通的进程的区别在于 **内核线程没有独立的地址空间**。内核进程 和 普通进程一样，可以被调度，也可以被抢占。

实际上，**内核线程也只能由其他内核线程创建**，内核是通过从 kthread 内核进程中衍生出所有新的内核线程来自动处理这一点。

新的任务是由 kthread 内核进程通过 `clone()` 系统调用而创建的。

- **最后线程程终止**

一般来说，进程的析构是自身引起的，它发生在进程调用 `exit()` 系统调用时，可能显示调用，也可能隐式从某个程序的主函数返回（比如，C 语言编译器会在 `main()` 函数的返回点后面放置调用 `exit()` 的代码），但是如果进程接受到它不能处理也不能忽略的信号或者异常时，它可能就会被动终结。这里是通过 `do_exit()` 函数来完成。

当然父进程已经退出了，就要为它的子进程找养父，如果找不到就会变成孤儿进程，交给 init 进程管理。



## 进程的调度时机

<u>进程调度算法也称 CPU 调度算法，毕竟进程是由 CPU 调度的。</u>

当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。

有两种调度的方式，分别是「**非抢占式调度**」和「**抢占式调度**」

<u>**非抢占式**的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。</u>

<u>而**抢占式调度**，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。</u>

常见的调度算法：

- 先来先服务调度算法
- 最短作业优先调度算法
- 高响应比优先调度算法
- 时间片轮转调度算法
- 最高优先级调度算法
- 多级反馈队列调度算法

### 进程调度算法

#### 先来先服务调度算法

最简单的一个调度算法，就是非抢占式的**先来先服务**（First Come First Severd, FCFS）算法了

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/进程调度算法01.4s2hgfyszfy0.png)

每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择另一个进程接着运行。

这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，**不利于短作业**。

所以，先来先服务调度算法有利于长作业运行，但是不利于短作业运行，

FCFS 对长作业有利，**适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统**。

#### 最短作业优先调度算法

**最短作业优先**（Shortest Job First, SJF）调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/进程调度算法02.1uorjth62fmo.png)

这显然对长作业不利，很容易造成一种极端现象。

比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。

#### 高响应比优先调度算法

前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。

那么，**高响应比优先**
（Highest Response Ratio Next, HRRN）调度算法主要是权衡了短作业和长作业。

每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：


$$\frac{等待时间+要求服务时间}{要求服务时间}$$

从上面的公式，可以发现：

- 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
- 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；

#### 时间片轮转调度算法

最古老、最简单、最公平且使用最广的算法就是时间片轮转（Round Robin, RR）调度算法。
。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/进程调度算法03.4144eayz4ns0.png)

每个进程被分配一个时间段，称为时间片（Quantum），也就是允许该进程在该时间段中运行。

如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；

如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；
另外，时间片的长度就是一个很关键的点：

如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；

如果设得太长又可能引起对短作业进程的响应时间变长。

通常时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。

#### 最高优先级调度算法

前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。

但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法。

进程的优先级可以分为，**静态优先级**或**动态优先级**：

- **静态优先级**：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- **动态优先级**：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。
  
该算法也有两种处理优先级高的方法，非抢占式和抢占式：

- 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
- 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

但是依然有缺点，可能会导致低优先级的进程永远不会运行。

#### 多级反馈队列调度算法

多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。

顾名思义：

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/进程调度算法04.5dtdedpqbhw0.png)

来看看，它是如何工作的：

设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短；

新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；

当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。

### 进程优先级的字段

首先用 `top` 或者 `ps -l` 查看进程会发现有 PR(PRI) 和 NI 两个字段：NI 是优先值，是用户层面的概念， PRI 是进程的实时优先级， 是给内核 (kernel) 看(用)的。

一般情况下，`PR=NI+20` , 如果一个进程的优先级 PR 是 20， 那么它的 NI(nice) 值就是 20-20=0。

进程调度优先级是从 -20 到 19，也就是 nice 值是 -20 到 19，一共 40 个级别，数字越大，表示进程的优先级越低。默认时候，进程的优先级是 0。

```
kendall@ubuntu:~$ ps -el
F S   UID    PID   PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD
4 S     0      1      0  2  80   0 -  9488 -      ?        00:00:03 systemd
1 S     0      2      0  0  80   0 -     0 -      ?        00:00:00 kthreadd
1 I     0      3      2  0  80   0 -     0 -      ?        00:00:00 kworker/0:0
1 I     0      4      2  0  60 -20 -     0 -      ?        00:00:00 kworker/0:0H
1 I     0      5      2  0  80   0 -     0 -      ?        00:00:00 kworker/u256:0
1 I     0      6      2  0  60 -20 -     0 -      ?        00:00:00 mm_percpu_wq
1 S     0      7      2  0  80   0 -     0 -      ?       
......
```

------

## 进程间通信

每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。

- **管道**

比如说在Linux终端敲下命令

```bash
ps -ef | grep bash
```

上面命令行里的「`|`」竖线就是一个管道，它的功能是将前一个命令（`ps -ef`）的输出，作为后一个命令（`grep bash`）的输入，从这功能描述，可以看出管道传输数据是单向的，如果想相互通信，我们需要创建两个管道才行。


同时，我们得知上面这种管道是没有名字，所以「`|`」表示的管道称为**匿名管道**，用完了就销毁。

管道还有另外一个类型是**命名管道**，也被叫做 `FIFO`，因为数据是先进先出的传输方式。

在使用命名管道前，先需要通过 `mkfifo` 命令来创建，并且指定管道名字：

> 怎么说：      
> - 管道分为匿名管道和有名管道，比如说在`shell`里面执行 `A | B`这里的`|`就是匿名管道，它是存在内存中的，并不是存在文件系统中的。然后匿名管道就单向的，它是通过`int pipe(int fd[2])`这个系统调用实现的，返回的是两个描述符，第一个是读文件描述符，第二个是写文件描述符。       
> - 那么管道是怎么实现跨越两个进程通讯的呢        
> 我们可以使用 `fork` 创建子进程，创建的子进程会复制父进程的文件描述符，两个进程就可以通过各自的 `fd` 写入和读取同一个管道文件实现跨进程通信了。
> - 对于**命名管道**，它可以在不相关的进程间也能相互通信。因为命令管道，提前通过`mkfifo myPipe`创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。
> - 不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 `lseek` 之类的文件定位操作。

```bash
$ mkfifo myPipe
```

`myPipe` 就是这个管道的名称，基于 `Linux` 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 `ls` 看一下，这个文件的类型是 `p`，也就是 `pipe`（管道） 的意思：

```
prw-r--r--   1 kendy  staff      0  4 19 12:16 myPipe
```

> 关键字：有名管道和匿名管道，单向的，用完即销毁，`pipe` 实现，返回两个文件描述符，不相关进程。缓存在内核中

-----

- **消息队列**

<u>管道的通信方式效率是很低的，因此管道不适合进程间频繁地交换数据。</u>

<u>对于这个问题，消息队列模式可以解决。比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去消息队列读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。</u>

再来，<u>**消息队列是保存在内核中的消息链表**，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），</u>消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以<u>每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。</u>

消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。

消息这种模型，两个进程之间的通信就像平时发邮件一样，你来一封，我回一封，可以频繁沟通了。

但邮件的通信方式存在不足的地方有两点，一是通信不及时，二是附件也有大小限制，这同样也是消息队列通信不足的点。

<u>**消息队列不适合比较大数据的传输**，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。</u>在 Linux 内核中，会有两个宏定义 MSGMAX 和 MSGMNB，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。

<U>消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。</U>

> A --> 消息队列 --> B，消息链表，消息快，有大小，不适合大数据，用户态 <--> 内核态


----
- **共享内存**

<u>消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那共享内存的方式，就很好的解决了这一问题。</U>

现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。

<u>共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。</U>

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/共享内存.39h8pfoxm8g0.png)

> 虚拟内存 指向 物理内存

----

- **信号量**

用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。

为了防止多进程竞争共享资源，而造成的数据错乱，信号量就是实现一个保护机制，使得共享的资源在任何时刻只能被一个进程访问。

**信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，**

信号量有两种原子操作
  -  P 操作
  -  V 操作

> 使得共享资源在同一时刻只能被一个进程访问


----
- **信号**

上面说的进程间通信，都是常规状态下的工作模式。对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。


在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 `kill -l` 命令，查看所有的信号：

```bash
$ kill -l
 1) SIGHUP	 2) SIGINT	 3) SIGQUIT	 4) SIGILL
 2) SIGTRAP	 6) SIGABRT	 7) SIGEMT	 8) SIGFPE
 3) SIGKILL	10) SIGBUS	11) SIGSEGV	12) SIGSYS
1)  SIGPIPE	14) SIGALRM	15) SIGTERM	16) SIGURG
2)  SIGSTOP	18) SIGTSTP	19) SIGCONT	20) SIGCHLD
3)  SIGTTIN	22) SIGTTOU	23) SIGIO	24) SIGXCPU
4)  SIGXFSZ	26) SIGVTALRM	27) SIGPROF	28) SIGWINCH
5)  SIGINFO	30) SIGUSR1	31) SIGUSR2	
```

信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产生。用户进程就可以对信号进行处理。

> 异步通信

- **Socket**

前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想**跨网络与不同主机上的进程之间通信**，就需要 Socket 通信了。

实际上，Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。

创建 socket 的系统调用：

```cpp
int socket(int domain, int type, int protocal)
```

创建 `Socket` 的时候，可以指定网络层使用的是 `IPv4` 还是 `IPv6`，传输层使用的是 `TCP` 还是 `UDP`。


> 不同主机之间通信


----
----

### 管道的创建与原理

匿名管道的创建，需要通过下面这个系统调用：
```cpp
int pipe(int fd[2])
```

这里表示创建一个匿名管道，并返回了**两个描述符**，一个是管道的读取端描述符 `fd[0]`，另一个是管道的写入端描述符 `fd[1]`。注意，这个匿名管道是特殊的文件，**只存在于内存，不存于文件系统中**。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/管道01.4a64wuvff780.png)

其实，所谓的管道，就是内核里面的一串缓存。从管道的一端写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，**管道传输的数据是无格式的流且大小受限**。

### 那么管道是怎么实现跨越两个进程通讯的呢

我们可以使用 `fork` 创建子进程，创建的子进程会复制父进程的文件描述符，这样就做到了两个进程各有两个「 `fd[0]` 与 `fd[1]`」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。

管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，为了避免这种情况，通常的做法是：

- 父进程关闭读取的 `fd[0]`，只保留写入的 `fd[1]`；
- 子进程关闭写入的 `fd[1]`，只保留读取的 `fd[0]`；

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/管道02.5l8wczaemy80.png)

所以说如果需要双向通信，则应该创建两个管道。

到这里，我们仅仅解析了使用管道进行父进程与子进程之间的通信，但是在我们 shell 里面并不是这样的。

在 `shell` 里面执行 `A | B`命令的时候，A 进程和 B 进程都是 `shell` 创建出来的子进程，`A` 和 `B` 之间不存在父子关系，它俩的父进程都是 `shell`。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/管道03.3prebw44s740.png)


所以说，在 `shell` 里通过「`|`」匿名管道将多个命令连接在一起，实际上也就是创建了多个子进程，那么在我们编写 `shell` 脚本时，能使用一个管道搞定的事情，就不要多用一个管道，这样可以减少创建子进程的系统开销。

我们可以得知，对于匿名管道，它的通信范围是存在父子关系的进程。因为管道没有实体，也就是没有管道文件，只能通过 `fork` 来复制父进程 `fd` 文件描述符，来达到通信的目的。

另外，对于**命名管道**，它可以在不相关的进程间也能相互通信。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。

不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 `lseek` 之类的文件定位操作。

> 怎么说：      
> - 管道分为匿名管道和有名管道，比如说在`shell`里面执行 `A | B`这里的`|`就是匿名管道，它是存在内存中的，并不是存在文件系统中的。然后匿名管道就单向的，它是通过`int pipe(int fd[2])`这个系统调用实现的，返回的是两个描述符，第一个是读文件描述符，第二个是写文件描述符。       
> - 那么管道是怎么实现跨越两个进程通讯的呢        
> 我们可以使用 `fork` 创建子进程，创建的子进程会复制父进程的文件描述符，两个进程就可以通过各自的 `fd` 写入和读取同一个管道文件实现跨进程通信了。
> - 对于**命名管道**，它可以在不相关的进程间也能相互通信。因为命令管道，提前通过`mkfifo myPipe`创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。
> - 不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 `lseek` 之类的文件定位操作。

### 信号量的两种原子操作

信号量表示资源的数量，控制信号量的方式有两种原子操作：

- 一个是 P 操作，这个操作会把信号量减去 -1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
- 另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；

P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。

接下来，举个例子，如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为 1。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/信号量01.674t2zu9m040.png)

具体的过程如下：

进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。
若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。
直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。
可以发现，信号初始化为 1，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。

另外，在多进程里，每个进程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个进程能密切合作，以实现一个共同的任务。

例如，进程 A 是负责生产数据，而进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A 必须先生产了数据，进程 B 才能读取到数据，所以执行是有前后顺序的。

那么这时候，就可以用**信号量来实现多进程同步的方式**，我们可以初始化信号量为 0。
 
![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/信号量02.14intk7e6wxs.png)

具体过程：

- 如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；
- 接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；
- 最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。

可以发现，信号初始化为 0，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执行。


----

## 多线程和多线程的应用

同一个进程内部有多个线程，所有的线程共享同一个进程的内存空间，进程中定义的全局变量会被所有的线程共享，比如有全局变量`int i = 10`，这一进程中所有并发运行的线程都可以读取和修改这个`i`的值，而多个线程被`CPU`调度的顺序又是不可控的，所以对临界资源的访问需要注意安全。

我们必须知道，**做一次简单的`i = i + 1`在计算机中并不是原子操作，会首先从内存中取出`i`值后，放入寄存器，然后对寄存器中的`i`值`+1`,最后把寄存器中的`i`值放回内存**，而线程的切换有可能发生在上述任何一个环节中间，所以不同的操作顺序很有可能带来意想不到的结果。

> 汇编指令的执行顺序

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/汇编指令执行顺序.rqmyoks7ljk.png)

> 从上图可以发现，只是单纯给 i 加上数字 1，在 CPU 运行的时候，实际上要执行 3 条指令。



但是，虽然多线程存在一些线程安全问题，但是线程也带来的很多好处。首先，原先顺序执行的程序（暂时不考虑多进程）可以被拆分成几个独立的逻辑流，这些逻辑流可以独立完成一些任务（最好这些任务是不相关的）。

比如 `QQ` 可以一个线程处理聊天一个线程处理上传文件，两个线程互不干涉，在用户看来是同步在执行两个任务，试想如果只有一个线程线性完成这个任务的话，在数据传输完成之前用户聊天被一直阻塞会是多么尴尬的情况。

另外，我们通常只会去说同一进程的多个线程共享进程的资源，但是每个线程特有的部分却很少提及，除了标识线程的`tid`，每个线程还有自己独立的栈空间，线程彼此之间是无法访问其他线程栈上内容的。

而作为处理机调度的最小单位，线程调度只需要保存线程栈、寄存器数据和程序计数器`PC`即可，相比进程切换开销要小很多。

### 什么时候用多进程，什么时候用多线程

https://blog.csdn.net/yu876876/article/details/82810178

* 频繁修改：需要频繁创建和销毁的优先使用**多线程**
* 计算量：需要大量计算的优先使用**多线程**  因为需要消耗大量`CPU`资源且切换频繁，所以多线程好一点
* 相关性：任务间相关性比较强的用**多线程**，相关性比较弱的用**多进程**。因为线程之间的数据共享和同步比较简单。
* 多分布：可能要扩展到多机分布的用**多进程**，多核分布的用**多线程**。

但是实际中更常见的是进程加线程的结合方式，并不是非此即彼的。


## 为什么会有线程安全问题

当多个线程同时共享同同一个**全局变量或静态变量**，做写的操作时，可能会发生数据冲突问题，也就是线程安全问题。但是做读的操作不会发生线程安全问题

**如何解决多线程之间线程安全问题**

实现 线程同步 和 锁

## 进程_线程的互斥与同步的实现和使用

在 进程/线程 并发执行的过程中，进程/线程之间存在协作的关系，例如有互斥、同步的关系。

为了实现 进程/线程 间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：

- 锁：加锁、解锁操作；
- 信号量：P、V 操作；

这两个都可以方便地实现 进程/线程 互斥，而「信号量」比「锁」的功能更强一些，它还可以方便地实现 进程/线程 同步。

## 进程同步方式

信号量和管程机制

* **信号量**：信号量可以说是类似一个计数器，它控制这个资源最多能被多少个进程进行访问。[见上面进程间通信的信号量的PV操作初始化为0的时候就实现了进程间同步](#信号量的两种原子操作)

* **管程**: 信号量机制功能强大，但使用时对信号量的操作分散，而且难以控制，读写和维护都很困难。因此后来又提出了一种**集中式同步进程**——管程。其基本思想是**将共享变量和对它们的操作集中在一个模块中**，操作系统或并发程序就由这样的模块构成。这样模块之间联系清晰，便于维护和修改，可以保证正确性。 

* **优缺点**： 

  * 1）信号量（Semaphore）及 PV 操作
  
   优：PV操作能够实现对**临界区**的管理要求；实现简单；允许使用它的代码休眠，持有锁的时间可相对较长。 

   缺：信号量机制必须有**公共内存**，不能用于分布式操作系统，这是它最大的弱点。信号量机制功能强大，但使用时对信号量的操作分散，而且难以控制，读写和维护都很困难。加重了程序员的编码负担；核心操作 P-V 分散在各用户程序的代码中，不易控制和管理；一旦错误，后果严重，且不易发现和纠正。 

> 临界区 管理，锁时间长，有 公共内存，操作分散，不利管理，错误难纠正


  * 管程
  
   优： 集中式同步进程——管程。其基本思想是将共享变量和对它们的操作集中在一个模块中，操作系统或并发程序就由这样的模块构成。这样模块之间联系清晰，便于维护和修改，易于保证正确性。 

   缺：如果一个分布式系统具有多个CPU，并且每个CPU拥有自己的私有内存，它们通过一个局域网相连，那么这些原语将失效。而管程在少数几种编程语言之外又无法使用，并且，这些原语均未提供机器间的信息交换方法。 

   > 集中同步，同一模块，有些编程语言无法使用。没有机器间信息交换方法

## 线程同步的方式

实现线程间同步的方法：

**互斥量，自旋锁，读写锁，条件变量**

- **互斥量**：比如说有两个线程，线程 1 和线程 2，分别充当生产者与消费者的角色，那么这两个线程就很有可能同时去操作临界资源，如果同时去操作临界资源的话就会引起线程同步问题，互斥量的话就是来解决这个问题，当一个线程，比如说线程 1 在操作临界资源的时候，它就会阻止另外的线程去访问这个临界资源。其实引发线程同步问题的最根本原因是**这两个线程的指令是交叉执行的**，互斥量能够保证指令执行的原子性，也就是说先执行完线程 1 的指令再执行线程2的指令，或者先执行完线程 2 的指令再执行线程1的指令。保证他们之间不会出现交叉执行的情况。互斥量也称为**互斥锁**，它要么处于加锁状态要么处于解锁状态。保证资源访问的串行。操作系统提供的 API 是 `pthread_mutex_t`。

- **自旋锁**：其实自旋锁和互斥锁的原理是一样的，都是在使用临界资源之前加一个锁，阻止其他线程对它进行访问，完成之后再把锁给释放掉，保证临界资源的串行访问。但是它和互斥锁还是存在差别的，使用自旋锁的线程会一直循环反复检查锁的变量是否可用，因此**它不会让出CPU**，会处于忙等待的状态。其实自旋锁还是有很多好处的，它避免了进程或者线程上下文切换的开销，如果锁使用的时间不是很长的话，使用自旋锁的代价也是很小的，同时在操作系统内部很多地方使用的是自旋锁而不是互斥量的。这里还要提一点就是**自旋锁不适合在单核`CPU`中使用**。因为自旋锁在等待的时候并不会释放`CPU`，而是死循环地去等待。会引起其他的进程或者线程无法去执行。操作系统提供的API是`pthread_spinlock_t `。

- **读写锁**: 读写锁和互斥锁还有自旋锁是类似的，但是做了一些改进，基于临界资源的考量，因为在开发环境中，临界资源很可能会出现多读少写的特性，就比如有一个数据库存储的是历史订单信息，而这些订单我们一般只是去查询很少去改变它，这个存储历史订单的数据库就属于多读少写的临界资源，如果在读写的时候也给它加锁，这样的话效率会很低的。读写锁的话是一种特殊的自旋锁，**它允许多个读者同时读取临界资源，但是不允许多个写操作同时访问这个资源**。在操作系统中提供的API是`thread_rwlock_t`，读锁是通过`thread_rwlock_rdlock`来加的，写锁是通过`thread_rwlock_wdlock`来加的.

- **条件变量**：条件变量是一种先对复杂的线程同步方法，它允许线程睡眠，在满足一定条件的时候再唤醒线程，就是当满足条件时，可以向这个线程发送信号，唤醒这个线程。因为在生产者和消费者模型中是存在问题的，举个例子，比如当缓冲区小于或者等于 0 时，这时候应该不允许消费者继续消费，消费者必须等待，当缓冲区满的时候，这个时候应该不允许生产者往里面生成数据了，生产者必须处于等待状态。条件变量呢就是对这个问题进行了约束，当缓冲区为 0 的时候，如果有生产者生产一个产品，那么就要唤醒可能等待的消费者；当缓冲区满的时候，如果有消费者消费了产品，就需要唤醒其他可能在等待的生产者。操作系统提供的`API`是`pthread_cont_t`来定义的,等待是通过`pthread_cont_wait`定义的，,唤醒是通过`pthread_cont_notify`定义的。

> 互斥量：保证只有一个进程去操作 临界资源，同步问题是因为两个指令交叉执行，所以需要保证原子性。   
> 自旋锁：加锁，保证串行执行，但是不会让出 CPU ，反复检查锁是是否可用，     
> 读写锁：考虑临界资源多读少写，允许多读不允许多写      
> 条件变量：适当的时候唤醒线程，缓冲区为 0 消费者等待，缓冲区满了，生产者等待


## 经典同步问题

### 哲学家就餐问题

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结/哲学家问题.2n2iy1dghiq0.png)

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。



```c
#define N 5

void philosopher(int i) {
    while(TRUE) {
        think();
        take(i);       // 拿起左边的筷子
        take((i+1)%N); // 拿起右边的筷子
        eat();
        put(i);
        put((i+1)%N);
    }
}
```

为了防止死锁的发生，可以设置两个条件：

- 必须同时拿起左右两根筷子；
- 只有在两个邻居都没有进餐的情况下才允许进餐。

```c
#define N 5
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think(i);
        take_two(i);
        eat(i);
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    check(i);
    up(&mutex);
    down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}

```

### 读者写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

即：读者只会读取数据，不会修改数据，而写者即可以读也可以修改数据。

一个整型变量 `count` 记录在对数据进行读操作的进程数量，一个互斥量 `count_mutex` 用于对 `count` 加锁，一个互斥量 `data_mutex` 用于对读写的数据加锁。

```c
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
    while(TRUE) {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);//最后一个读者要对数据进行解锁，防止写进程无法访问
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}
```

## 怎么回收线程？有哪几种方法？

- **等待线程结束**：`int pthread_join(pthread_t tid, void** retval);`

  主线程调用，等待主线程退出并回收其资源，类似于进程中`wait/waitpid`回收僵尸进程，调用`pthread_join`的线程会被阻塞。

  - `tid`：创建线程时通过指针得到tid值。

  - `retval`：指向返回值的指针。

- **结束线程**：`pthread_exit(void *retval);`

  子线程执行，用来结束当前线程并通过`retval`传递返回值，该返回值可通过`pthread_join`获得。

  - `retval`：同上。

- **分离线程**：`int pthread_detach(pthread_t tid);`

  主线程、子线程均可调用。主线程中`pthread_detach(tid)`，子线程中`pthread_detach(pthread_self())`，调用后和主线程分离，子线程结束时自己立即回收资源。

  - `tid`：同上。


> 使用 pthread_join 阻塞，等待子进程运行结束，并回收资源    
> 通过 pthread_detach(tid) 分离主进程和父进程，子进程结束自己回收


----

## Linux理论上最多可以创建多少个进程

## 一个进程可以创建多少线程，和什么有关

在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址 空间的范围也不同。比如最常⻅的 32 位和 64 位系统，如下所示:

![](https://img-blog.csdnimg.cn/20210715092026648.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70)


通过这里可以看出:

- 32 位系统的内核空间占用 1G ，位于最高处，剩下的 3G 是用户空间;
  - 32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程
  
- 64 位系统的内核空间和用户空间都是 128T ，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。
  - 64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。

> 一个进程最多可以创建多少个线程,和 虚拟内存控件上限 和 系统参数限制 有关

- **进程的虚拟空间上限**：因为创建一个线程，操作系统需要分配一个栈空间，如果线程数量越多，所需要的栈空间就越大，那么虚拟内存就会占用越多
- **系统参数的限制**：虽然 linux 没有内核参数来控制单个进程创建的最大线程数目，但是有系统级别的参数控制整个操作系统创建线程的最大数目

可以使用 `ulimit -a` 命令来查看创建线程时默认分配给线程的栈空间大小为 8M

```
kendall@MacBook ~ % ulimit -a
-t: cpu time (seconds)              unlimited
-f: file size (blocks)              unlimited
-d: data seg size (kbytes)          unlimited
-s: stack size (kbytes)             8192    //我的系统默认是 8192
-c: core file size (blocks)         0
-v: address space (kbytes)          unlimited
-l: locked-in-memory size (kbytes)  unlimited
-u: processes                       2784
-n: file descriptors                2560
```


## 守护进程、僵尸进程和孤儿进程

### 守护进程

指在后台运行的，没有控制终端与之相连的进程。它独立于控制终端，周期性地执行某种任务。`Linux`的大多数服务器就是用守护进程的方式实现的，如`web`服务器进程`http`等

创建守护进程要点：

（1）**让程序在后台执行**。方法是调用`fork()`产生一个子进程，然后使父进程退出。

（2）**调用`setsid()`创建一个新会话**。因为控制终端、登录会话和进程组通常是从父进程继承下来的，守护进程要摆脱它们，不受它们的影响，方法是调用`setsid()`使子进程成为一个会话组长。`setsid()`调用成功后，子进程成为新的会话组长和进程组长，并与原来的登录会话、进程组和控制终端脱离。

（3）**禁止进程重新打开控制终端**。经过以上步骤，子进程已经成为一个无终端的会话组长，但是它可以重新申请打开一个终端。为了避免这种情况发生，可以通过使进程不再是会话组长来实现。再一次通过`fork()`创建新的子进程，使调用`fork`的进程退出。

（4）**关闭不再需要的文件描述符**。子进程从父进程继承打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。首先获得最高文件描述符值，然后用一个循环程序，关闭从`0`到最高文件描述符值的所有文件描述符。

（5）**将当前目录更改为根目录**。

（6）子进程从父进程继承的文件创建屏蔽字可能会拒绝某些许可权。为防止这一点，**使用`unmask(0)`将屏蔽字清零**。

（7）**处理信号**，因为对于服务器来说，一个请求到来的时候一般是先生成一个子进程请求，如果子进程等待父进程捕获状态的话，那么子进程就会成为一个僵尸进程，占用系统资源，那么父进程等待子进程结束的话就会增加父进程的负担，从而影响服务器的并发性能。所以在`Linux`下可以简单地将`SIGCHLD`信号的操作设为`SIG_IGN`。这样，子进程结束时不会产生僵尸进程。

### 孤儿进程

如果父进程先退出，子进程还没退出，那么子进程的父进程将变为`init`进程。（注：任何一个进程都必须有父进程）。

 一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被`init`进程(进程号为 1 )所收养，并由`init`进程对它们完成状态收集工作。 

### 僵尸进程

如果子进程先退出，父进程还没退出，那么子进程必须等到父进程捕获到了子进程的退出状态才真正结束，否则这个时候子进程就成为僵尸进程。

设置**僵尸进程的目的**是维护子进程的信息，以便父进程在以后某个时候获取。这些信息至少包括进程ID，进程的终止状态，以及该进程使用的CPU时间，所以当终止子进程的父进程调用`wait`或`waitpid`时就可以得到这些信息。如果一个进程终止，而该进程有子进程处于僵尸状态，那么它的所有僵尸子进程的父进程`ID`将被重置为`1`（init进程）。继承这些子进程的`init`进程将清理它们（也就是说`init`进程将`wait`它们，从而去除它们的僵尸状态）。

### 孤儿进程和僵尸进程分别是什么，怎么形成的？

https://www.cnblogs.com/Anker/p/3271773.html

* 孤儿进程是父进程退出后它的子进程还在执行，这时候这些子进程就成为孤儿进程。孤儿进程会被`init`进程收养并完成状态收集。
* 僵尸进程是指子进程完成并退出后父进程没有使用`wait()`或者`waitpid()`对它们进行状态收集，这些子进程的进程描述符仍然会留在系统中。这些子进程就成为僵尸进程。

### 如何避免僵尸进程？

- 通过`signal`(SIGCHLD, SIG_IGN)通知内核回收子进程。如果不想让父进程挂起，可以在父进程中加入一条语句：`signal`(SIGCHLD,SIG_IGN);表示父进程忽略SIGCHLD信号，该信号是子进程退出的时候向父进程发送的。

- 父进程调用`wait/waitpid`等函数等待子进程结束，如果尚无子进程退出`wait`会导致父进程阻塞。`waitpid`可以通过传递`WNOHANG`使父进程不阻塞立即返回。

- 如果父进程很忙可以用`signal`注册信号处理函数，在信号处理函数调用`wait/waitpid`等待子进程退出。

- 通过两次调用`fork`。父进程首先调用`fork`创建一个子进程然后`waitpid`等待子进程退出，子进程再`fork`一个孙进程后退出。这样子进程退出后会被父进程等待回收，而对于孙子进程其父进程已经退出所以孙进程成为一个孤儿进程，孤儿进程由`init`进程接管，孙进程结束后，`init`会等待回收。

第一种方法忽略`SIGCHLD`信号，这常用于并发服务器的性能的一个技巧因为并发服务器常常`fork`很多子进程，子进程终结之后需要服务器进程去`wait`清理资源。如果将此信号的处理方式设为忽略，可让内核把僵尸子进程转交给`init`进程去处理，省去了大量僵尸进程占用系统资源。

> 《Linux系统下创建守护进程(Daemon)》：https://blog.csdn.net/linkedin_35878439/article/details/81288889

> 《01_fork()的使用》：https://blog.csdn.net/WUZHU2017/article/details/81636851

## 用户态和内核态的区别

内核态与用户态是操作系统的两种运行级别,当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；反之，当程序运行在0级特权级上时，就可以称之为运行在内核态。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。

**这两种状态的主要差别是**： 

（1）处于**用户态**执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理机是**可被抢占**的 ； 

（2）而处于**核心态**执行中的进程，则能访问所有的内存空间和对象，且所占有的处理机是**不允许被抢占**的。

通常来说，以下三种情况会导致用户态到内核态的切换：

1）系统调用

这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如使用`fork()`实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

2）异常

当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

3）外围设备的中断

当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。


------ 

## 阻塞与非阻塞的区别

- 函数或方法调用的时候，是否立即返回，立即返回就是非阻塞调用，不立即返回就是阻塞调用。

- 阻塞与非阻塞的区别在于，调用者是否还能干其他事。 阻塞，调用者就只能干等； 非阻塞，调用者可以先去忙会别的，不用一直等。

## 线程池问题

[C++线程池](https://www.freesion.com/article/2943146109/)

[C++ 线程池学习笔记（面试吹牛逼）](https://www.freesion.com/article/34631158849/)

### 线程池的概念

在开发过程中，可能很多任务并行执行，比如说，我之前设计过一个爬虫系统，当时有一些网站响应很慢，如果要保证每秒钟能够访问更多的页面，就需要启动多个线程，但是线程开的过多就带来过多的调度开销，所以这时候可以使用线程池，使用多个线程，无限制循环等待队列，进行计算和操作。帮助快速降低和减少性能损耗。

### 线程池的组成

- 线程池管理器：初始化和创建一定数量的线程，启动和停止线程，调配任务；也就是管理线程池，
- 工作线程：线程池中等待并执行分配的任务，可以使用 **条件变量**实现等待与通知机制.
- 任务接口：添加任务的接口，用来提供给 工作线程 调度任务的执行。
- 任务队列：用于存放没有处理的任务，提供一种 缓冲机制，同时具有调度功能，高优先级的任务放在队列前面

### 实现线程池的具体步骤

1.设置一个生产者消费者队列，作为**临界资源**

2.初始化 n 个线程，并让其运行起来，加锁去任务队列去任务运行

3.当任务入队列为空的时候，所有线程阻塞

4.当生产者队列来了一个任务后，先对队列加速，把任务挂载到队列上，然后使用条件变量去通知阻塞中一个线程处理任务，当任务处理完成之后，该线程会被重新放回线程池中，以供其他的任务调用。

![](https://cdn.jsdelivr.net/gh/kendall-cpp/blogPic@main/寻offer总结02/线程池01.1t1l6oxbz400.jpeg)


### 线程池工作的四种情况

1. 没有任务要执行，缓冲队列为空

![](https://www.freesion.com/images/297/3805f625e05f8e2d1d0b69910323d7a9.png)

2. 队列中任务数量，小于等于线程池中线程任务数量

![](https://www.freesion.com/images/465/b72937b576e8e3e4a0b14ff5a9b3a1b9.png)

3. 任务数量大于线程池数量,缓冲队列未满

![](https://www.freesion.com/images/555/3bc05a0abf3eff2c7e25427e1c2636bb.png)

4. 任务数量大于线程池数量，缓冲队列已满

![](https://www.freesion.com/images/620/4a50fc4f32e13a1761c2e687a58a83a4.png)

### 如何保证线程池是线程安全的

> 我写的线程池是使用POSIX写的。线程池整个项目中包括两个类：一个是Task类，用于描述执行一个任务的方法（一个函数）和执行这个任务所需要的参数（函数的参数）。另外一个类就是我们的线程池类ThreadPool类，在线程池中主要有两个队列，一个是 Task 类队列，用于存放要处理的任务。一个是线程池中存放线程的数组。

在线程池类中通过一个互斥锁（pthread_mutex_t类型变量）来实现线程池的线程安全性。每次往任务队列中添加任务、或者从任务队列中取任务前都要使用pthread_mutex_lock函数加一把锁，然后对任务队列进行操作。操作完后再使用pthread_mutex_unlock释放这个锁，从而实现对任务队列的互斥访问。也就是说每次想要对任务队列进行操作都需要：

`pthread_mutex_lock(&mutex);`

增加任务到任务队列或者从任务队列取任务;

`pthread_mutex_unlock(&mutex);`

来互斥的访问任务队列。以避免多个线程同时操作任务队列造成死锁。如任务队列只剩下一个空位置，但是多个线程同时向任务队列中添加任务；任务队列中只剩下一个任务，但是多个线程同时到任务队列中取任务；使用互斥锁来实现线程安全的访问任务队列。

### 当有一个任务进入任务队列时，其他阻塞线程是如何获取并执行这个任务的

在 ThreadPool 的构造函数中根据我们指定的个数使用 new 来动态创建线程数组。然后使用 `pthread_create` 为每个线程注册线程启动函数，在线程启动函数中每一个前程启动函数都要对任务队列进行实时监控，使得一旦有任务到来我们的空闲线程就去任务队列获取并执行任务，每个线程函数都是互斥的访问任务队列。

由于刚开始时没有任务到来，我们可以在线程函数中使用条件变量（`pthread_cond_t`）使得的线程都处于阻塞状态`phtread_cond_wait(&cond, &mutex)`。一旦有任务到来就使用`pthread_cond_signal(&cond)`来激活一个因为该条件而阻塞的线程。当然也可以使用`pthread_cond_broadcast(&cond)`

**线程函数中的代码架构如下**:

```c
void * threadFunc(void *paramter)//线程中的线程启动函数，相当于执行任务的函数

{
    ...

    pthread_mutex_lock(&mutex);//加锁对任务队列互斥访问

    while(任务队列为空)

    {
        pthread_cond_wait(&cond, &mutex);

    }

    ....//获取任务

    pthread_mutex_unlock(&mutex);

    ....//执行任务

}
```

注意：

- 1）这里我们首先使用了 `pthread_mutex_lock` 对任务队列加锁实现多个线程互斥访问任务队列。

- 2）判断任务队列为空时，使用的是 `while` 循环而不是 `if` ，这里可以防止出现“虚假唤醒”的情况。

- 3）当程序执行到 `pthread_cond_wait` 函数内部时，首先会释放掉互斥锁，线程函数阻塞到这里，不再往下运行。当有任务时会以“信号”的形式唤醒该线程函数，加锁并继续往下执行。所以 `pthread_cond_wait `函数` = pthread_mutex_unlock+pthread_mutex_lock` 这两个函数功能。

**向任务队列中添加任务的代码架构如下**：

```c
void addTast()

{
     pthread_mutex_lock(&mutex);//因为要互斥的访问任务队列，加锁

     ....//将任务添加到任务队列

     pthread_cond_signal(&cond);或者是pthread_cond_broadcast(&cond);//发送信号给一个因为该条件而阻塞的线程

     pthread_mutex_unlock(&mutex);//解锁

}
```